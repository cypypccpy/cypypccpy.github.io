<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yuanpei Chen</title>
  
  <meta name="author" content="Yuanpei Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/icon.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yuanpei Chen | 陈源培</name>
              </p>
              <p>I am a fourth-year undergraduate student at <a href=https://www.scut.edu.cn/en/>South China University of Technology</a>, working with Prof. <a href="https://www.yangyaodong.com/">Yaodong Yang</a> at <a href=https://english.pku.edu.cn/>Peking University</a>. I also had the privilege of working closely with Prof. <a href="https://www.bristolroboticslab.com/robot-teleoperation">Chenguang Yang</a> at SCUT and Prof. <a href="https://zsdonghao.github.io/">Hao Dong</a> at Peking University. In 2023, I am fortunately working as an visiting researcher at <a href=https://www.stanford.edu/>Stanford University</a>, advised by Prof. <a href="https://tml.stanford.edu/people/karen-liu">Karen Liu</a> and Prof. <a href="https://profiles.stanford.edu/fei-fei-li">Fei-Fei Li</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:yuanpeic@stanford.edu">Email</a> &nbsp/&nbsp
                <a href="data/Curricula_Vitae.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?hl=en&user=LR4CHSkAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/cypypccpy/">Github</a>&nbsp/&nbsp
                <!-- <a href="images/WeChat.jpg">WeChat</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yuanpei_part.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/yuanpei_part.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>
                <span class="php">Research</span></heading>
              <p>
                I'm interested in <strong>robotics</strong>, <strong>dexterous manipulation</strong>, <strong>reinforcement learning</strong>, and <strong>sim-to-real transfer</strong>. My goal is to let the robot perform various <strong>cool</strong> behaviors in the real world as in the simulation.
              </p>
              <br>
          
                <!-- <img src='images/coverv4.jpg' width="700"> -->
        </tr>
        </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>
              <span class="php">Representative publication</span></heading>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
          <td style="padding:10px;width:30%;vertical-align:middle">
            <img src='images/seqdex.gif' width="100%">
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://sequential-dexterity.github.io/">
              <papertitle>Sequential Dexterity: Chaining Dexterous Policies for Long-Horizon Manipulation</papertitle>
            </a>
            <br>
            <strong>Yuanpei Chen*</strong>,
              <a href="https://www.chenwangjeremy.net/">Chen Wang*</a>, 
							<a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>,
              <a href="https://profiles.stanford.edu/c-karen-liu?tab=teaching">C. Karen Liu</a>,
              <br>
              <em>CoRL</em>, 2023, Accepted
              <br>
              <a href="https://sequential-dexterity.github.io/">Project Page</a>
              <!-- / -->
              <!-- <a href="https://arxiv.org/abs/2206.08686">ArXiv</a> -->
              <!-- / -->
              <!-- <a href="https://github.com/PKU-MARL/DexterousHands">Code</a> -->
              <p></p>
              <p>
                We present Sequential Dexterity, a general system based on reinforcement learning (RL) that chains multiple dexterous policies for achieving long-horizon task goals.
              </p>
          </td>
        </tr>

        <tr>
          <td style="padding:10px;width:30%;vertical-align:middle">
            <img src='images/dynamic_handover.gif' width="100%">
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://binghao-huang.github.io/dynamic_handover/">
              <papertitle>Dynamic Handover: Throw and Catch with Bimanual Hands</papertitle>
            </a>
            <br>
            <a href="https://binghao-huang.github.io/">Binghao Huang*</a>, 
            <strong>Yuanpei Chen*</strong>,
            <a href="https://tianhaowuhz.github.io/">Tianyu Wang</a>, 
            <a href="https://yzqin.github.io/">Yuzhe Qin</a>,
            <a href="https://www.yangyaodong.com/">Yaodong Yang</a>,
            <a href="https://natanaso.github.io/">Nikolay Atanasov</a>,
            <a href="https://xiaolonw.github.io/">Xiaolong Wang</a>
            <br>
            <em>CoRL</em>, 2023, Accepted
            <br>
            <a href="https://binghao-huang.github.io/dynamic_handover/">Project Page</a>
            <!-- /
            <a href="https://arxiv.org/abs/2206.08686">ArXiv</a>
            /
            <a href="https://github.com/PKU-MARL/DexterousHands">Code</a> -->
            <p></p>
            <p>
              We design a system with two multi-finger hands attached to robot arms to solve the dynamic handover problem. We train our system using Multi-Agent Reinforcement Learning in simulation and perform Sim2Real transfer to deploy on the real robots.
            </p>
          </td>
        </tr>

          <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/quick_demo3.gif' width="100%">
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://bi-dexhands.ai/">
                <papertitle>Towards Human-Level Bimanual Dexterous Manipulation with Reinforcement Learning</papertitle>
              </a>
              <br>
              <strong>Yuanpei Chen</strong>,
              <a href="https://tianhaowuhz.github.io/">Tianhao Wu</a>, 
							<a href="https://github.com/Shengjie-bob">Shengjie Wang</a>,
              <a href="https://github.com/waterhorse1">Xidong Feng</a>,
              <a href="https://github.com/jiechuanjiang">Jiechuang Jiang</a>,
              <a href="https://cypypccpy.github.io/">Stephen Marcus McAleer</a>,
              <a href="https://zsdonghao.github.io">Hao Dong</a>,
              <a href="https://z0ngqing.github.io">Zongqing Lu</a>,
              <a href="http://www.stat.ucla.edu/~sczhu/">Song-chun Zhu</a>,
              <a href="https://www.yangyaodong.com/">Yaodong Yang</a>
              <br>
              <em>NeurIPS</em>, 2022, Accepted
              <br>
              <a href="https://bi-dexhands.ai/">Project Page</a>
              /
              <a href="https://arxiv.org/abs/2206.08686">ArXiv</a>
              /
              <a href="https://github.com/PKU-MARL/DexterousHands">Code</a>
              <p></p>
              <p>
                We propose a bimanual dexterous manipulation benchmark (Bi-DexHands) according to literature from cognitive science for comprehensive reinforcement learning research.
              </p>
            </td>
          </tr>
        </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>
                <span class="php">Collaborative publication</span></heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <td style="padding:10px;width:30%;vertical-align:middle">
          <img src='images/ReDMan.png' width="100%">
        <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="pdf/RedMan.pdf">
              <papertitle>ReDMan: Reliable Dexterous Manipulation with Safe Reinforcement Learning</papertitle>
            </a>
            <br>
            <a href="https://gengyiran.github.io/">Yiran Geng*</a>, 
            <a href="https://github.com/zmsn-2077">Jiaming Ji*</a>,
            <strong>Yuanpei Chen*</strong>,
            <a href="https://geng-haoran.github.io/">Haoran Geng</a>,
            <a href="https://fangweizhong.xyz/">Fangwei Zhong</a>,
            <a href="https://www.yangyaodong.com/">Yaodong Yang</a>
            <br>
            <a href="pdf/RedMan.pdf">Paper</a>
            /
            <a href="https://github.com/PKU-Alignment/ReDMan">Code</a>
            <br>
            <em>Machine Learning (Journal), Accepted</em>
            <p></p>
            <p>
              We introduce ReDMan, an open-source simulation platform that provides a standardized implementation of safe RL algorithms for Reliable Dexterous Manipulation. 
            </p>
          </td>
        </tr>
          
          <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/detailed.png' width="100%">
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/openbidexhand">
                <papertitle>Learning a Universal Human Prior for Dexterous Manipulation from Human Preference</papertitle>
              </a>
              <br>
              <a href="https://quantumiracle.github.io/webpage/">Zihan Ding</a>,
              <strong>Yuanpei Chen</strong>,
              <a href="https://allenzren.github.io/">Allen Z. Ren</a>,
              <a href="https://sites.google.com/view/gugurus/home">Shixiang Shane Gu</a>,
              <a href="https://zsdonghao.github.io/">Hao Dong</a>,
              <a href="https://sites.google.com/view/cjin/home">Chi Jin</a>
              <br>
              <a href="https://arxiv.org/abs/2304.04602">Arxiv</a>
              /
              <a href="https://sites.google.com/view/openbidexhand">Project Page</a>
              /
              <a href="https://sites.google.com/view/openbidexhand/home/datacollection?authuser=0">Provide Your Preference</a></li>
              /
              <a href="https://cypypccpy.github.io/">Code (Coming soon)</a></li>
              <br>              
              <p>We propose a framework to learn a universal human prior using direct human preference feedback over videos, for efficiently tuning the RL policy on 20 dual-hand robot manipulation tasks in simulation, without a single human demonstration</p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/myo2.png' width="100%">
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/myochallenge">
                <papertitle>MyoChallenge: Die reorientation</papertitle>
              </a>
              <br>
              <a href="https://cypypccpy.github.io/">Yiran Geng</a>,
              <a href="https://cypypccpy.github.io/">Boshi An</a>,
              <a href="https://cypypccpy.github.io/">Yifan Zhong</a>,
              <a href="https://cypypccpy.github.io/">Jiaming Ji</a>,
              <strong>Yuanpei Chen</strong>
              <br>
              <a href="https://sites.google.com/view/myochallenge">Challenge Page</a>
              /
              <a href="https://github.com/PKU-MARL/MyoChallenge">Code</a>
              /
              <a href="pdf/DieRotation_NIPS22.pdf">Slides</a></li>
              /
              <a href="https://sites.google.com/view/myochallenge#h.t3275626vjox">Talk</a></li>
              <br>
              <b>First Place in NeurIPS 2022 Challenge Track (1st in 340 submissions from 40 teams)</b>
              <p></p>
              
              <p>Reconfiguring a die to match desired goal orientations. This task require delicate coordination of various muscles to manipulate the die without dropping it. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/teaser_aij.png' width="100%">
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/trustdehands/">
                <papertitle>Safe Multi-Agent Reinforcement Learning for Multi-Robot Control</papertitle>
              </a>
              <br>
              <a href="https://cypypccpy.github.io/">Shangding Gu*</a>,
              <a href="https://cypypccpy.github.io/">Jakub Grudzien Kuba*</a>, 
              <strong>Yuanpei Chen</strong>,
              <a href="https://cypypccpy.github.io/">Yali Du</a>,
              <a href="https://cypypccpy.github.io/">Long Yang</a>,
              <a href="https://cypypccpy.github.io/">Alois Knoll</a>,
              <a href="https://www.yangyaodong.com/">Yaodong Yang</a>
              <br>
              <em>Journal of Artificial Intelligence (AIJ)</em>, 2022, Accepted
              <br>
              <a href="https://sites.google.com/view/aij-safe-marl/">project Page</a>
              /
              <a href="https://sites.google.com/view/aij-safe-marl/">Code</a>
              <!-- /
              <a href="https://github.com/PKU-MARL/DexterousHands">code</a> -->
              <p></p>
              <p>
                We investigate safe MARL for multi-robot control on cooperative tasks, in which each individual robot has to not only meet its own safety constraints while maximising their reward, but also consider those of others to guarantee safe team behaviours.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/pipeline.jpg' width="100%">
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/rlafford/">
                <papertitle>End-to-End Affordance Learning for Robotic Manipulation</papertitle>
              </a>
              <br>
              <a href="https://cypypccpy.github.io/">Yiran Geng*</a>,
              <a href="https://cypypccpy.github.io/">Boshi An*</a>, 
							<a href="https://cypypccpy.github.io/">Haoran Geng</a>,
              <strong>Yuanpei Chen</strong>,
              <a href="https://www.yangyaodong.com/">Yaodong Yang</a>,
              <a href="https://zsdonghao.github.io">Hao Dong</a>
              <br>
              (*equal contribution)
              <br>
              <em>ICRA</em>, 2022, Accepted
              <br>
              <a href="https://sites.google.com/view/rlafford/">Project Page</a>
              /
              <a href="https://arxiv.org/abs/2209.12941">ArXiv</a>
              <!-- /
              <a href="https://github.com/PKU-MARL/DexterousHands">code</a> -->
              <p></p>
              <p>
                In this study, we take advantage of visual affordance by using the contact information generated during the RL training process to predict contact maps of interest.
              </p>
            </td>
          </tr>



          <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/SimTwin.jpg' width="100%">
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.cambridge.org/core/journals/robotica/article/zeroshot-simtoreal-transfer-of-reinforcement-learning-framework-for-robotics-manipulation-with-demonstration-and-force-feedback/8F7630528F363B7624020FEA4A94B06B#">
                <papertitle>Zero-Shot Sim-to-Real Transfer of Reinforcement Learning Framework for Robotics Manipulation with Demonstration and Force Feedback</papertitle>
              </a>
              <br>
              <strong>Yuanpei Chen</strong>,
              <a href="https://cypypccpy.github.io/">Chao Zeng</a>,
              <a href="https://cypypccpy.github.io/">Zhiping Wang</a>, 
							<a href="https://arclab.hku.hk/index.html">Peng Lu</a>,
              <a href="https://www.bristolroboticslab.com/robot-teleoperation">Chenguang Yang</a>
              <br>
              <em>IEEE-ARM</em>, 2022, Outstanding Paper Selected for Robotica Journal
              <!-- &nbsp <font color="red"><strong>Outstanding Paper Selected for Robotica Journal</strong></font> -->
              <br>
              <a href="https://www.cambridge.org/core/journals/robotica/article/zeroshot-simtoreal-transfer-of-reinforcement-learning-framework-for-robotics-manipulation-with-demonstration-and-force-feedback/8F7630528F363B7624020FEA4A94B06B#">Project Page</a>
              /
              <a href="https://www.cambridge.org/core/journals/robotica/article/zeroshot-simtoreal-transfer-of-reinforcement-learning-framework-for-robotics-manipulation-with-demonstration-and-force-feedback/8F7630528F363B7624020FEA4A94B06B#">Paper</a>
              /
              <a href="https://github.com/cypypccpy/Isaac-ManipulaRL">Code</a>
              <p></p>
              <p>
                We propose Simulation Twin (SimTwin) : a deep reinforcement learning framework that can help directly transfer the model from simulation to reality without any real-world training.
              </p>
            </td>
          </tr>

        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading><span class="php">Experience</span></heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="10"><tbody>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/stanford_university.png", width="90%"></td>
            <td width="80%" valign="center">
              <b>Stanford University</b>, CA
              <br> 2022.10 - Present
              <br>
              <br> <b>Visiting Research Student</b>
              <br> Advisor: Prof. <a href="https://tml.stanford.edu/people/karen-liu">Karen Liu</a> and Prof. <a href="https://profiles.stanford.edu/fei-fei-li">Fei-Fei Li</a>
            </td>
          </tr>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/peking_university.png", width="90%"></td>
            <td width="80%" valign="center">
              <b>Peking University</b>, China
              <br> 2022.03 - 2023.07
              <br>
              <br> <b>Visiting Research Student</b>
              <br> Advisor: Prof. <a href="https://www.yangyaodong.com/">Yaodong Yang</a>
            </td>
          </tr>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/scut.jpg", width="90%"></td>
            <td width="80%" valign="center">
              <b>South China University of Technology</b>, China
              <br> 2019.09 - 2023.07
              <br>
              <br> <b>B.S. </b>
              <br> Advisor: Prof. <a href="https://www.bristolroboticslab.com/robot-teleoperation">Chenguang Yang</a>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><span class="php">Miscellaneous</span></heading>
              <p>
                I was quite into competitive robot&#x1f916; and used to compete in <a href="https://www.robomaster.com/en-US">RoboMaster</a>&#127941; and ICRA 2021 AI Challenge.
              </p>
            </td>
          </tr>
        </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
              Template stolen from <a href="https://jonbarron.info/">Jon Barron</a>. Thanks for stopping by :)
              <br> Last updated: Nov 6, 2021 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
